from typing import Union
from langchain_core.documents import Document
import logging
from ..chunks import BaseOperator 
import re
logger = logging.getLogger(__name__)

__OPERATOR__ = {}

def register_operator(name:str):
    def wrapper(cls):
        if name in __OPERATOR__:
            logger.error(f"Operator {name} is already registered.")
            raise ValueError(f"Operator {name} is already registered.")
        __OPERATOR__[name] = cls
        return cls
    return wrapper

def get_operator(name:str):
    if name not in __OPERATOR__:
        logger.error(f"Operator {name} is not registered.")
        raise ValueError(f"Operator {name} is not registered.")
    return __OPERATOR__[name]

@register_operator("markdown-splitter")
class MarkdownSplitter(BaseOperator):
    """
    ğŸš€ğŸš€ğŸš€ è‹¥éœ€è¦æ›´å¤æ‚çš„é€»è¾‘,è¯·ä½¿ç”¨æŠ½è±¡è¯­æ³•æ ‘
    ===== é€»è¾‘ =====
    1. åŸºæœ¬é€»è¾‘
        - #ç¬¦å·åˆ†å—
        - \n ç¬¦å·åˆ†å—
        -- å¤„ç†æ— ç”¨å­—ç¬¦ä¸² å¦‚\t
    2. ç‰¹æ®Šé€»è¾‘ - éœ€è¦åå¤„ç†
        - è¡Œé—´å…¬å¼
        - è¡Œé—´ä»£ç å—
        - è¡Œå†…å†…å®¹å…¬å¼ç­‰ç­‰

    ===== ä¼˜å…ˆçº§è¡¨ =====
    | ä¼˜å…ˆçº§  | è§„åˆ™æè¿°           | å¤‡æ³¨                        |
    | ------ | ----------------- | -------------------------- |
    | 1.2    | äº•å·åˆ†å—           | ç®€å•ç²—æš´                     |
    | 1      | è¡Œé—´å…¬å¼ã€ä»£ç       | è¡Œé—´å…¬å¼å†…å®¹ä¹Ÿå—åˆ°å­—ç¬¦ä¸²å…¨å±€åŒ¹é… |
    | 2      | æ¢è¡Œç¬¦åˆ†å—ã€        | ç®€å•                        |
    | 1.1    | è¡Œå†…å†…å®¹           | è¡Œå†…å†…å®¹                    |
    | 99     | å¤„ç†æ— ç”¨å­—ç¬¦ä¸²      | å…¶ä»–å†…å®¹                    |

    ===== æ³¨æ„äº‹é¡¹ =====
    1. #ç¬¦å·åˆ†åˆ°å“ªä¸ªå­—æ ‡é¢˜ï¼Ÿè‹¥å­æ¨¡å—è¿‡å°ï¼Œè¿˜éœ€è¦åˆ†å—å—
        - è§£å†³æ–¹æ³•ï¼šè®¾å®šåˆ†å—å¤§å°å‚è€ƒå€¼ï¼Œé™¤äº†æ ‡é¢˜å’Œå‰¯æ ‡é¢˜å¤–ï¼Œå¢åŠ åˆå¹¶é€»è¾‘
    2. å­æ¨¡å—è¿‡å°,å¯ä»¥ä½¿ç”¨recursiveCharacterTextSplitterè¿›è¡ŒäºŒæ¬¡åˆ†å—

    ===== å¤æ‚åº¦ =====
    - æ—¶é—´å¤æ‚åº¦,O(n),nä¸ºæ–‡æœ¬é•¿åº¦
    langchainçš„å®ç°æ–¹å¼å¤æ‚åº¦ä¸ºO(xn), xä¸ºHeaderæ•°é‡
    """
    DEFAULT_HEADER_KEYS = {
        "#": "Header 1",
        "##": "Header 2",
        "###": "Header 3",
        "####": "Header 4",
        "#####": "Header 5",
        "######": "Header 6",
    }

    def __init__(self, 
                 headers_to_split_on: Union[dict[str, str], None] = None,
                 strip_headers: bool = True,  # noqa: FBT001,FBT002
                 **kwargs):
        if headers_to_split_on is None:
            self.headers_to_split_on = self.DEFAULT_HEADER_KEYS
        else:
            self.headers_to_split_on = headers_to_split_on
        
        self.strip_headers = strip_headers
        self.kwargs = kwargs
        self.chunks : list[Document] = []  # å­˜å‚¨åˆ†å—åçš„æ–‡æœ¬
        self.current_chunk = Document(page_content="")  # å½“å‰åˆ†å—å†…å®¹
        self.current_header_stack: list[tuple[int, str]] = []  # å½“å‰æ ‡é¢˜æ ˆ
        
    def execute(self, text: str) -> list[Document]:
        """
        æ‰§è¡Œåˆ†å—æ“ä½œ
        :param text: è¾“å…¥çš„æ–‡æœ¬
        :return: åˆ†å—åçš„æ–‡æœ¬åˆ—è¡¨
        """
        # ===== ä¼˜å…ˆçº§ 1 =====
        # è¡Œé—´å…¬å¼ã€ä»£ç 
        text = self._split_by_math_and_code(text)
        # ===== ä¼˜å…ˆçº§ 1.1 =====
        # è¡Œå†…å†…å®¹ Â· preliminary: è®¤ä¸ºè¡Œé—´å†…å®¹å·²ç»è¢«è§£å†³äº†ã€ä¸ä¼šè¢«å†æ¬¡åŒ¹é…
        # ä½¿ç”¨è¯¥æ–¹æ³•ï¼Œè¯¯æŠ¥æ¦‚ç‡è¿œå¤§äºè¡Œé—´å…¬å¼ã€ä»£ç 
        text = self._split_by_inline_content(text)
        # ===== ä¼˜å…ˆçº§ 1.2 =====
        # äº•å·åˆ†å—
        text = self._split_by_headers(text)

        return text

    def _split_by_headers(self, text: str):
        pass

    def _split_by_inline_content(self, text: str):
        """
        å¤„ç†è¡Œå†…å†…å®¹, ä¹Ÿä¼šå‡ºç°è¯¯æŠ¥
        """
        # 1. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è¡Œå†…å…¬å¼
        inline_math_pattern = r"\$.*?\$"
        text = re.sub(inline_math_pattern, self._post_process_inline_math, text)

        # 2. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è¡Œå†…ä»£ç å—
        inline_code_pattern = r"`.*?`"
        text = re.sub(inline_code_pattern, self._post_process_inline_code, text)

        return text
    
    def _split_by_math_and_code(self, text: str):
        """
          è¯¥æ–¹æ³•å¯èƒ½å­˜åœ¨è¯¯æŠ¥æƒ…å†µ,æ¯”å¦‚åœ¨å­—ç¬¦ä¸²ä¸­åŒ…å«è¿‡æ»¤è§„åˆ™
          å¯ä»¥å¢åŠ åŒ¹é…è§„åˆ™ï¼Œå‡å°‘è¯¯æŠ¥, æ¯”å¦‚\nç¬¦å·
        """
        # 1. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è¡Œé—´å…¬å¼
        math_pattern1 = r"```math \n.*?```"
        math_pattern2 = r"\$\$.*?\$\$"
        # TODO: æµ‹è¯•
        # re.DOTALL, è·¨è¡ŒåŒ¹é…
        text = re.sub(math_pattern2, self._post_process_math, text, flags=re.DOTALL)
        text = re.sub(math_pattern1, self._post_process_math, text, flags=re.DOTALL)

        # é»˜è®¤r"```math.*?```"å…¶ä¸­çš„å†…å®¹å·²è¢«å¤„ç†ï¼Œæ›¿æ¢ä¸ºäº†xxx
        # 2. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è¡Œé—´ä»£ç å—
        langs = ["python", "javascript", "java", "c++", "c#", "go", "ruby", "php", "typescript", "yaml"]
        tmp = "|".join(langs)
        code_pattern1 = rf"```({tmp})\n.*?```"
        text = re.sub(code_pattern1, self._post_process_code, text, flags=re.DOTALL)

        return text

    def _post_process_math(self, match: re.Match):
        """
        å¤„ç†è¡Œé—´å…¬å¼
        """
        matched = match.group(0)
        matched = "www.math.com"  # TODO: å¤„ç†è¡Œé—´å…¬å¼
        return matched

    def _post_process_code(self, match: re.Match):
        """
        å¤„ç†è¡Œé—´ä»£ç å—
        """
        matched = match.group(0)
        matched = "www.code.com"  # TODO: å¤„ç†è¡Œé—´ä»£ç å—
        return matched

    def _post_process_inline_math(self, match: re.Match):
        """
        å¤„ç†è¡Œå†…å…¬å¼
        """
        matched = match.group(0)
        matched = "www.inline-math.com"  # TODO: å¤„ç†è¡Œå†…å…¬å¼
        return matched
    
    def _post_process_inline_code(self, match: re.Match):
        """
        å¤„ç†è¡Œå†…ä»£ç å—
        """
        matched = match.group(0)
        matched = "www.inline-code.com"  # TODO: å¤„ç†è¡Œå†…ä»£ç å—
        return matched

if __name__ == "__main__":
    # æµ‹è¯• langchain_markdown_splitter
    splitter = get_operator("markdown-splitter")()
    with open("README.md", "r", encoding="utf-8") as f:
        text = f.read()
    chunks = splitter.execute(text)
    print(chunks)  # è¾“å‡ºåˆ†å—ç»“æœ